{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vacuum Gauge Classifier\n",
    "Advanced tool for classifying vacuum gauges \n",
    "\n",
    "* [Setup](#setup)\n",
    "    * [Environment](#env)\n",
    "    * [Data Retrieval](#retrieval)\n",
    "    * [Data Normalization](#norm)\n",
    "    * [Data Masking](#masking)\n",
    "* [Dataset Creation](#create)\n",
    "    * [Level Data](#level)\n",
    "    * [Plot Levels](#plotlevels)\n",
    "    * [Generate Dataset](#gen)\n",
    "    * [Convert Dataset](#convert)\n",
    "* [K-Neighbours Classifiaton](#kneighbours)\n",
    "    * [Holdout](#holdout)\n",
    "    * [Parameter Optimization](#crossvalidate)\n",
    "    * [Final Evaluation](#eva)\n",
    "    * [Exhaustive Evaluation](#exhaust)\n",
    "* [Use Model](#use)\n",
    "    * [Save Model](#save)\n",
    "    * [Load Model](#load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='setup'> Setup </a>\n",
    "## <a id='env'>Environment </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytimber\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "db = pytimber.LoggingDB()\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='create'> Dataset Creation </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lockout():\n",
    "    resp = input(\"Are you sure you want to reset? 1: Yes, 0: No\")\n",
    "    while True:\n",
    "        try:\n",
    "            resp = int(resp)\n",
    "        except:\n",
    "            print(\"Please type a number, 0 or 1\")\n",
    "            resp = input(\"Are you sure you want to reset? 1: Yes, 0: No\")\n",
    "            continue\n",
    "        if resp == 1:\n",
    "            return 2\n",
    "        elif resp == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            print(\"Please type a number, 0 or 1\")\n",
    "            resp = input(\"Are you sure you want to reset? 1: Yes, 0: No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='gen'> Generate Dataset </a>\n",
    "Use CSV file containing probe/gauge information and their ground truth to generate a 2D array containing the pressure levels (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_data(df=pd.read_csv(r'CompleteProbeCatalogue2.csv'), variant=\"default\", limit=None, cuts = 9, verbose=False, showPlot=False, reset = 0):\n",
    "    if reset == 1: reset = lockout()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Shape of Data: (%d,%d)\" % df.shape)\n",
    "    data = []\n",
    "    count = 0\n",
    "    limit = df.shape[0] if limit is None else limit \n",
    "    \n",
    "    progressBar = IntProgress(min=0, max=limit,description='Progress:',bar_style='info') # instantiate the bar\n",
    "    display(progressBar)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        gauge_id = row['Probe ID']\n",
    "        if row['Response'] == \"UNDETERINED\":\n",
    "            print(\"Skipping UNDETERMINED gauge {}\".format(gauge_id))\n",
    "            continue\n",
    "        if (count > limit):\n",
    "            break\n",
    "            \n",
    "        file_name = \"probe_%s_fill%d.p\"%(gauge_id,row['Fill'])\n",
    "        press_file_name = \"pressure_levels_for_fill_%d_w_%d_cuts.p\"%(row['Fill'],cuts)\n",
    "        variant_folder = os.path.join(os.getcwd(),'data','probes',str(row['Fill']),gauge_id,variant)\n",
    "        main_folder = os.path.join(os.getcwd(),'data','probes',str(row['Fill']),gauge_id)\n",
    "        if not os.path.exists(variant_folder):\n",
    "            os.makedirs(variant_folder)\n",
    "        if os.path.isfile(os.path.join(main_folder,file_name)) and reset == 0:\n",
    "            if verbose:\n",
    "                print(\"Loading existing data for {} in Fill {}\".format(gauge_id,row['Fill']))\n",
    "            pgd = pickle.load(open(os.path.join(main_folder,file_name),\"rb\"))\n",
    "            if os.path.isfile(os.path.join(variant_folder,press_file_name)):\n",
    "                pressure_levels = pickle.load(open(os.path.join(variant_folder,press_file_name),\"rb\"))\n",
    "            else:\n",
    "                pressure_levels = level_data(pgd.pressure_readings[pgd.mask],cuts)\n",
    "                pickle.dump(pressure_levels, open( os.path.join(variant_folder,press_file_name),\"wb\"))\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Saving data for %s\"%gauge_id)\n",
    "            pgd = processed_gauge_data(gauge_id, row['Fill'])\n",
    "            try:\n",
    "                pressure_levels = pgd.generate_data(cuts=cuts)\n",
    "            except RuntimeError:\n",
    "                print(\"Could not generate data for {} in fill {}\".format(gauge_id,fill))\n",
    "                continue\n",
    "            pickle.dump( pgd, open( os.path.join(main_folder,file_name), \"wb\" ))\n",
    "            pickle.dump(pressure_levels, open( os.path.join(variant_folder,press_file_name), \"wb\"))\n",
    "\n",
    "        data.append(pressure_levels)\n",
    "\n",
    "        if showPlot:\n",
    "            pgd.plot_data()\n",
    "        if verbose:\n",
    "            print(\"Probe %s label:%s\"%(gauge_id,row['Steepness']))\n",
    "            print(\"%sClassificaton:%s %s \\n\"%(color.BOLD,color.END,row['Response']))\n",
    "        count += 1\n",
    "        progressBar.value += 1\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='convert'> Convert to SciKit Learn Dataset </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-13a2c28cfd57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mget_or_create_gauge_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'CompleteProbeCatalogue2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ProbeDataSet.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlockout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreset\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"datasets\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cuts\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def get_or_create_gauge_dataset(X = None, cuts = None, df = pd.read_csv(r'CompleteProbeCatalogue2.csv'), reset = 0, variant=\"default\", file_name=\"ProbeDataSet.csv\"):\n",
    "    if reset == 1: reset = lockout()\n",
    "    \n",
    "    if cuts is not None:\n",
    "        folder=os.path.join(os.getcwd(),\"data\",\"datasets\",\"cuts\"+str(cuts),variant)\n",
    "        file_name = file_name.replace(\".\", \"_%d_cuts.\"%cuts)\n",
    "    else:\n",
    "        folder=os.path.join(os.getcwd())\n",
    "    \n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "\n",
    "    print(\"%sAccessing:%s %s\\n\"% (color.BOLD,color.END, os.path.join(folder,file_name))) \n",
    "    \n",
    "    # Ensure Indices align by resetting\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Get uncategorisable gauges \n",
    "    bad_indices = df.index[df['Response'].str.contains(\"UNDETERMINED\")].tolist() \n",
    "    # Get Duplicates\n",
    "    duplicate_indices = np.nonzero(df.duplicated(subset=[\"Probe ID\",\"Fill\"],keep='first'))[0]\n",
    "    \n",
    "    # Remove uncategorisable & duplicate gauges\n",
    "    droppable_indices = np.unique(np.concatenate((bad_indices,duplicate_indices),axis=0))         \n",
    "    df = df.drop(droppable_indices)\n",
    "    y = df.pop('Response').replace(to_replace=['NORMAL','COUPLED'],value=[0,1])\n",
    "    if os.path.isfile(os.path.join(folder,file_name)) and reset==0:\n",
    "        if cuts is not None:\n",
    "            files = os.listdir(folder)             \n",
    "            for i in range(0,len(files)):\n",
    "                print(\"%s%d: %s%s\" %(color.BOLD,i,color.END,files[i]))\n",
    "            print(\"Type number of desired dataset to load it\")\n",
    "            while True:\n",
    "                resp = input(\">>>\")\n",
    "                try:\n",
    "                    file_name = files[int(resp)]\n",
    "                except:\n",
    "                    continue\n",
    "                break\n",
    "        print(\"Loading Dataset from Memory...\")\n",
    "        X = pd.read_csv(os.path.join(folder,file_name))\n",
    "        y = X.pop('Response')\n",
    "    else:\n",
    "        print(\"Loading Dataset from passed Variables...\")\n",
    "    \n",
    "        X = pd.DataFrame(np.array(X), columns = ['Interval '+str(i) for i in range(len(X[0]))])\n",
    "        print(\"Loaded X to shape {} for y of shape {}\".format(X.shape,y.shape))\n",
    "        if X.shape[0] > y.shape[0]:\n",
    "            X = X.drop(droppable_indices)\n",
    "        print(\"Changed X to shape {} for y of shape {}\".format(X.shape,y.shape))\n",
    "        dataset = pd.concat((X,y),axis=1)\n",
    "        dataset.to_csv(os.path.join(folder,file_name), index=False, header = True)\n",
    "    \n",
    "    return X,y.astype(int), pd.concat((df['Probe ID'],df['Fill']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Multiple Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8b75d172607a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CompleteProbeCatalogue2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_cuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_fill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Remove Duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Probe ID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Fill\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def create_datasets(df=pd.read_csv(\"CompleteProbeCatalogue2.csv\"), min_cuts = 1, max_cuts = 8, min_fill = None, max_fill = None, reset = 0, variant = \"default\", verbose=False):\n",
    "    if reset == 1: reset = lockout()\n",
    "    \n",
    "    # Remove Duplicates\n",
    "    df.drop_duplicates(subset=[\"Probe ID\",\"Fill\"],inplace=True)\n",
    "    df.sort_values(axis=0,by=\"Fill\",inplace=True)\n",
    "    if min_fill is not None and max_fill is not None:\n",
    "        df = df.loc[df.Fill >= min_fill].loc[df.Fill <= max_fill]\n",
    "        \n",
    "    datasets = []\n",
    "    for cut in range(min_cuts,max_cuts):\n",
    "        folder=os.path.join(os.getcwd(),\"data\",\"datasets\",\"cuts\"+str(cut),variant)\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        file_name = \"ProbeDataSet_%d_cuts.csv\"%(cut)\n",
    "        if os.path.isfile(os.path.join(folder,file_name)) and reset == 0:\n",
    "            print(\"%s already exists\"%file_name)\n",
    "            X,y,lookup = get_or_create_gauge_dataset(df = df,\n",
    "                                                     file_name=os.path.join(\"data\",\"datasets\",\"cuts\"+str(cut),variant,file_name),\n",
    "                                                     reset=reset)\n",
    "            datasets.append((X,y,lookup))\n",
    "        else:\n",
    "            data = setup_data(df=df, limit=None, variant=variant, cuts = cut, verbose=verbose, reset = reset)\n",
    "            X,y,lookup = get_or_create_gauge_dataset(X=data, df = df,\n",
    "                                                     file_name=os.path.join(\"data\",\"datasets\",\"cuts\"+str(cut),variant,file_name),\n",
    "                                                     reset=reset)\n",
    "            datasets.append((X,y,lookup))\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='kneighbours'> K-Nearest-Neighbours Classification </a>\n",
    "## <a id='holdout'> Setup Training and Testing sets </a>\n",
    "Split the data into a test and training set using a random seed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, LeaveOneOut, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "def prepare_sets(X,y, seed = 3):\n",
    "    # Optional: Normalize to mean = 0 var = 1?\n",
    "\n",
    "    X_train, X_test, X_train_labels, X_test_labels = train_test_split( X, y,\n",
    "                                                                       test_size=0.2, random_state=seed)\n",
    "    print ('%sTrain set:%s Data %s Labels %s'% (color.BOLD,color.END, X_train.shape,  X_train_labels.shape))\n",
    "    print ('%sTest set:%s  Data %s Labels %s'% (color.BOLD,color.END, X_test.shape,  X_test_labels.shape))\n",
    "    return X_train, X_test, X_train_labels, X_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='crossvalidate'> Grid Search Cross-Validation </a>\n",
    "Split dataset differently over multiple iterations to improve generalization. <br>\n",
    "Test over range of k-values using parameter_grid. <br>\n",
    "Uses full features (X) and targets (y) since the cross-validation splits the dataset 5 times. <br>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/cross_validation.html\">SciKit Learn Documentation: Cross Validation<a> <br>\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\" alt=\"Grid Search Workflow\" width=\"400\" align=\"left\"> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have used a Stratified K fold, which preserves the original distribution of the dataset (about 50% of each class) in both the training_set and testing_set.<br>\n",
    "Since the dataset is split in 5, we have 20% of the data put aside for testing and 80% for training. Hence we need 5 passes to test all possibilities. <br>\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0071.png\" alt=\"Stratified KFold\" width=\"600\" align=\"left\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_sets(X, y, verbose = True,\n",
    "                        cv_splitter = StratifiedKFold(n_splits=5,random_state=0)):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "    \n",
    "    cv_splitter = StratifiedShuffleSplit(n_splits=10,test_size=0.2,train_size=0.8,random_state=0)\n",
    "    average_cv_score = np.mean(cross_val_score(classifier, X, y, cv=cv_splitter))\n",
    "    print(\"Average CV score: %.3f\"%average_cv_score)\n",
    "    print ('%sTrain set:%s %d'% (color.BOLD,color.END, cv_splitter.train_size * len(X)))\n",
    "    print ('%sValidation set:%s %d'% (color.BOLD,color.END, cv_splitter.test_size * len(X)))\n",
    "    if verbose:\n",
    "        for training_indices, validation_indices in cv_splitter.split(X,y):\n",
    "            display(np.sort(training_indices)[0:5])\n",
    "            display(np.sort(validation_indices)[0:5])\n",
    "    return cv_splitter, average_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_optimal_k(cv_splitter,X,y,verbose=1,showPlot=True):\n",
    "    Ks = 20\n",
    "    acc = np.zeros((Ks,cv_splitter.get_n_splits(X)))\n",
    "    std = np.zeros((Ks,cv_splitter.get_n_splits(X)))\n",
    "    best_score, best_k = 0, None\n",
    "\n",
    "    progessBar = IntProgress(min=0, max=cv_splitter.get_n_splits(X)*Ks,description='Progress:',bar_style='info') # instantiate the bar\n",
    "    display(progessBar)\n",
    "\n",
    "    for k in range(0,Ks):\n",
    "        split_count = 0\n",
    "        scores = np.zeros(cv_splitter.n_splits)\n",
    "        for training_indices, testing_indices in cv_splitter.split(X,y):\n",
    "            X_train,X_train_labels = X.iloc[training_indices], y.iloc[training_indices]\n",
    "            X_test, X_test_labels = X.iloc[testing_indices], y.iloc[testing_indices]\n",
    "            model = KNeighborsClassifier(n_neighbors=k+1).fit(X_train,X_train_labels)\n",
    "            X_test_predictions = model.predict(X_test)\n",
    "            if verbose >= 2:\n",
    "                print(\"Model using k:%d\"%k)\n",
    "                print(\"Train set Accuracy: \", metrics.accuracy_score(X_train_labels, model.predict(X_train)))\n",
    "                print(\"Test set Accuracy: \", metrics.accuracy_score(X_test_labels, X_test_predictions))\n",
    "            score = metrics.accuracy_score(X_test_labels, X_test_predictions)\n",
    "            scores[split_count] = score\n",
    "            std_dev = np.std(X_test_predictions==X_test_labels)/np.sqrt(X_test_predictions.shape[0])\n",
    "            acc[k,split_count] = score\n",
    "            std[k,split_count] = std_dev\n",
    "            split_count += 1\n",
    "            progessBar.value += 1\n",
    "        if np.mean(scores) > best_score:\n",
    "            best_score = np.mean(scores)\n",
    "            best_k = k+1\n",
    "    mean_acc = np.mean(acc, axis=1)\n",
    "    mean_std = np.mean(std, axis=1)\n",
    "    best_neighbors = np.argmax(mean_acc)+1\n",
    "    if verbose >= 1:\n",
    "        print(\"%sMean Accuracies:%s\"% (color.BOLD,color.END))\n",
    "        display(pd.DataFrame(mean_acc).transpose())\n",
    "        print(\"\\n%sBest Accuracy:%s %.1f%%\" % (color.BOLD,color.END, np.max(mean_acc)*100))\n",
    "        \n",
    "        print(\"\\n%sBest K-value:%s %d\"% (color.BOLD,color.END, best_neighbors))\n",
    "    \n",
    "    if showPlot:\n",
    "        plt.figure()\n",
    "        plt.plot(range(1,Ks+1),mean_acc,'g')\n",
    "        plt.fill_between(range(1,Ks+1),mean_acc - 1 * mean_std,mean_acc + 1 * mean_std, alpha=0.10)\n",
    "        plt.legend(('Accuracy ', '$\\pm$3$\\sigma$'))\n",
    "        plt.ylabel('Accuracy ')\n",
    "        plt.xlabel('K-Value')\n",
    "        plt.xticks([i for i in range(1,Ks+1)])\n",
    "        plt.xlim((1,Ks+1))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return best_score, best_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generator\n",
    "Uses grid search (implemented as above) to find the optimal parameters. <br>\n",
    "This cell is essetially a compact form of the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generator(X,y,cv_splitter, scorer=metrics.make_scorer(metrics.accuracy_score), verbose = 1):\n",
    "    classifier = KNeighborsClassifier()\n",
    "    param_grid = {'n_neighbors': np.arange(1, 20)}\n",
    "    models = GridSearchCV(classifier, param_grid, cv=cv_splitter, iid = True, verbose=verbose, scoring = scorer) \n",
    "    models.fit(X,y)\n",
    "    print(\"%sOptimal neighbours:%s %d\\n%sScore:%s %.1f%%\"%(color.BOLD,color.END, models.best_params_['n_neighbors'],color.BOLD,color.END,models.best_score_*100))\n",
    "    return models.best_params_['n_neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_optimal_cuts(datasets):\n",
    "    best_score = -1.0\n",
    "    best_neighbors = -1\n",
    "    best_cut = -1\n",
    "    best_average = (-1,-1,-1)\n",
    "    for dataset in datasets:\n",
    "        X,y,lookup = dataset\n",
    "        X_train, X_test, X_train_labels, X_test_labels = prepare_sets(X,y, seed = 12)\n",
    "        cuts = X.shape[1]\n",
    "        print(\"\\n%sNumber of Cuts: %d %s\"%(color.BOLD,cuts,color.END))\n",
    "        cv_splitter, average_cv_score = cross_validate_sets(X_train, X_train_labels, verbose = False)\n",
    "        score, neighbours = find_optimal_k(cv_splitter,X_train,X_train_labels,verbose=1,showPlot=False)\n",
    "        if score > best_score and neighbours > 1:\n",
    "            best_score = score\n",
    "            best_cut = cuts\n",
    "            best_neighbors = neighbours\n",
    "        if average_cv_score > best_average[2]:\n",
    "            best_average = (cuts,neighbours,average_cv_score)\n",
    "    print(\"%sBest Performance%s for %d cuts and K = %d with %.1f%% accuracy\"%(color.BOLD,color.END,best_cut,best_neighbors,best_score*100))\n",
    "    print(\"%sBest Average%s for %d cuts and K = %d with %.1f%% accuracy\"%(color.BOLD,color.END,best_average[0],best_average[1],best_average[2]*100))\n",
    "    return best_cut, best_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='eva'>Final Evaluaton </a>\n",
    "Uses seeded training_set (not cross validated!) for a final evaluation of the model, including the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(y_test,yhat,labels=None):# Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, yhat, labels=labels)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Unexpected','Expected'],normalize= False,  title='Confusion matrix')\n",
    "    \n",
    "    return cnf_matrix\n",
    "\n",
    "def classic_eval(lookup,y,X_test,X_test_labels,variant, verbose=False):\n",
    "    print(X_test)\n",
    "    print(X_test_labels)\n",
    "    test_indices = X_test.index\n",
    "    test_set = lookup.iloc[test_indices]\n",
    "    pos = 0\n",
    "    curve_correct, gradient_correct = 0, 0\n",
    "    for index,row in test_set.iterrows():\n",
    "        file_name = \"probe_%s_fill%d.p\"%(row['Probe ID'],row['Fill'])\n",
    "        folder = os.path.join(os.getcwd(),'data','probes',row['Probe ID'],variant)\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        if verbose:\n",
    "            print(os.path.join(folder,file_name))\n",
    "        if os.path.isfile(os.path.join(folder,file_name)):\n",
    "            if verbose:\n",
    "                print(\"Loading existing data for %s\"%row['Probe ID'])\n",
    "            pgd = pickle.load(open(os.path.join(folder,file_name),\"rb\"))\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Saving data for %s\"%gauge_id)\n",
    "            pgd = processed_gauge_data(row['Probe ID'], int(row['Fill']))\n",
    "            try:\n",
    "                pgd.generate_data(cuts=cuts,get_levels=False)\n",
    "            except RuntimeError:\n",
    "                print(\"Could not generate data for {} in fill {}\".format(gauge_id,fill))\n",
    "                continue\n",
    "            pickle.dump( pgd, open( os.path.join(folder,file_name), \"wb\" ))\n",
    "\n",
    "        # Forward Fourier Transform\n",
    "        pressure_transform, spectrum, deltaT = forward_fourier_transform(pgd.time_readings,pgd.pressure_readings)\n",
    "        # Constrained Inverse Fourier Transform\n",
    "        time_constrained, signal_constrained = filtered_inverse_fourier_transform(pressure_transform,deltaT,spectrum[0],40)\n",
    "        # Curve Fitting\n",
    "        try:\n",
    "            fit1,fit2, coupled = fit_curves(time_constrained,signal_constrained,pgd.mask,verbose=False)\n",
    "        except UnboundLocalError:\n",
    "            print(\"Could not fit curves for {} in fill {}\".format(row['Probe ID'],row['Fill']))\n",
    "            pos+=1\n",
    "            continue\n",
    "        \n",
    "        f,ax,coupled2 = VG_analyzer_simple(row['Probe ID'],row['Fill'],plot=False)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Ground Truth: %d (test_labels) for index %d\"%(X_test_labels.loc[index],index)) #y.iloc[index]\n",
    "            print(\"Curve Fit Prediction: %s\"%coupled)\n",
    "            print(\"Gradient Prediction: %s\\n\"%coupled2)\n",
    "#         print(len(y))\n",
    "#         print(index)\n",
    "        if (coupled == X_test_labels.loc[index]):\n",
    "            curve_correct +=1\n",
    "        if (coupled2 == X_test_labels.loc[index]):\n",
    "            gradient_correct +=1\n",
    "        pos+=1\n",
    "    \n",
    "    print(\"Curve Fit Accuracy %.1f\"%(100*(float(curve_correct)/len(test_set))))\n",
    "    print(\"Curve Correct %d out of %d\"%(curve_correct,len(test_set)))\n",
    "    \n",
    "    print(\"Gradient Accuracy %.1f\"%(100*(float(gradient_correct)/len(test_set))))\n",
    "    print(\"Gradient Correct %d out of %d\"%(gradient_correct,len(test_set)))\n",
    "    \n",
    "def final_eval(datasets,best_cut,best_neighbors, eval_dataset = None, variant=\"default\", verbose=False, seed = 12, evaluate_classic=False):\n",
    "    X,y,lookup= datasets[(datasets[0][0].shape[1])+best_cut-2]\n",
    "    if eval_dataset is None:\n",
    "        X_train, X_test, X_train_labels, X_test_labels = prepare_sets(X,y, seed = seed)\n",
    "    else:\n",
    "        X_train, X_test, X_train_labels, X_test_labels = prepare_sets(X,y, seed = seed)\n",
    "        \n",
    "        eval_X,eval_X_labels,eval_lookup = eval_dataset\n",
    "        X_test = eval_X\n",
    "        X_test_labels = eval_X_labels\n",
    "        X_train = X\n",
    "        X_train_labels = y\n",
    "        \n",
    "    print(\"Y:{} X:{}\".format(len(y),len(X_test)))\n",
    "    classifier = KNeighborsClassifier(n_neighbors=best_neighbors)\n",
    "    print(\"%sNeighbors:%s %d\" % (color.BOLD,color.END,best_neighbors))\n",
    "    print(\"%sCuts:%s %d\" % (color.BOLD,color.END,X.shape[1]))\n",
    "    model = classifier.fit(X_train,X_train_labels)\n",
    "    yhat = model.predict(X_test)\n",
    "    xhat = model.predict(X_train)\n",
    "    training_std_dev = np.std(xhat==X_train_labels)/np.sqrt(xhat.shape[0]) # std error appropriate?\n",
    "    testing_std_dev = np.std(yhat==X_test_labels)/np.sqrt(yhat.shape[0]) # std error\n",
    "    print(\"%sTrain set Accuracy:%s %.3f \\xc2\\xb1 %.3f\" %(color.BOLD, color.END, metrics.accuracy_score(X_train_labels, xhat),training_std_dev))\n",
    "    print(\"%sTest set Accuracy:%s %.3f \\xc2\\xb1 %.3f\\n\" %(color.BOLD, color.END, metrics.accuracy_score(X_test_labels, yhat),testing_std_dev))\n",
    "    cnf_matrix = get_confusion_matrix(X_test_labels,yhat)\n",
    "    print(\"{}Classification Report{}\".format(color.BOLD,color.END))\n",
    "    print(classification_report(X_test_labels, yhat))\n",
    "    \n",
    "    if evaluate_classic:\n",
    "        classic_eval(lookup,y,X_test, X_test_labels, variant, verbose=verbose)\n",
    "    return model, X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='use'>Use Model</a>\n",
    "## <a id='save'>Store Model</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    print(\"{}Model Desc:{}\\n {}\".format(color.BOLD,color.END,model))\n",
    "    print(\"Please enter a name for your model\\n%sNote%s: no. of cuts will be appended)\"%(color.UNDERLINE,color.END))\n",
    "    folder = os.path.join(os.getcwd(),\"data\",\"models\",\"k_neighbours\")\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    while True:\n",
    "        resp = input(\">>>\")\n",
    "        try:\n",
    "            saved_model = dump(model, os.path.join(folder,str(resp)+\"_\"+str(best_cut)+'.joblib'))\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    print(\"Successfully saved model to {}\".format(str(resp)+\"_\"+str(best_cut)+'.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='load'>Load Model</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_model():\n",
    "    folder = os.path.join(os.getcwd(),\"data\",\"models\",\"k_neighbours\")\n",
    "    files = os.listdir(folder)\n",
    "    for i in range(0,len(files)):\n",
    "        print(\"%s%d: %s%s\" %(color.BOLD,i,color.END,files[i]))\n",
    "    print(\"Type number of desired model to load it\")\n",
    "    while True:\n",
    "        resp = input(\">>>\")\n",
    "        try:\n",
    "            file_name = files[int(resp)]\n",
    "        except:\n",
    "            continue\n",
    "        model = load(os.path.join(folder,file_name))\n",
    "        print(\"Model Loaded with %d neighbours\"%model.n_neighbors)\n",
    "        break\n",
    "    return model, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
